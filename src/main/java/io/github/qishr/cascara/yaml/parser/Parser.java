package io.github.qishr.cascara.yaml.parser;

import java.util.List;

import io.github.qishr.cascara.common.diagnostic.Reporter;
import io.github.qishr.cascara.yaml.ast.YamlMap;
import io.github.qishr.cascara.yaml.ast.YamlMappingEntry;
import io.github.qishr.cascara.yaml.ast.YamlNode;
import io.github.qishr.cascara.yaml.ast.YamlScalar;
import io.github.qishr.cascara.yaml.ast.YamlSequence;

/**
 * Parses the stream of tokens generated by the Tokenizer into an Abstract Syntax Tree (AST)
 * composed of YamlNode objects (YamlMap, YamlSequence, YamlScalar, etc.).
 */
public class Parser {

    private final Reporter reporter;
    private final List<Tokenizer.Token> tokens;
    private int current = 0;

    public Parser(Reporter reporter, List<Tokenizer.Token> tokens) {
        this.reporter = reporter;
        this.tokens = tokens;
    }

    /**
     * The main entry point for the parser.
     */
    public YamlNode parse() {
        consume(Tokenizer.TokenType.STREAM_START, "Expected beginning of token stream.");
        YamlNode root = parseRootBlockMap();
        consume(Tokenizer.TokenType.EOF, "Expected end of content.");
        consume(Tokenizer.TokenType.STREAM_END, "Expected end of token stream.");
        return root;
    }

    /// Log the current method name and upcoming tokens
    private void trace(String methodName) {
        reporter.reportTrace("L%d C%d I%d %28s: %s",
                tokens.get(current).line(),
                tokens.get(current).column(),
                current, methodName, upcomingTokens());
    }

    // Get next 4 tokens as a string.
    private String upcomingTokens() {
        StringBuilder sb = new StringBuilder();
        int distance = Math.min(tokens.size() - current, 4);
        for (int i = 0; i < distance; i++) {
            Tokenizer.Token token = tokens.get(current + i);
            sb.append(token.type());
            sb.append("(");
            sb.append(token.lexeme().replace("\n", "\\n").replace("\r", "\\r"));
            sb.append(") ");
        }
        return sb.toString();
    }

    // -------------------------------------------------------------------------
    // CORE PARSING METHODS
    // -------------------------------------------------------------------------

    /**
     * Determines the type of node (Map, Sequence, or Scalar) and calls the appropriate handler.
     */
    private YamlNode parseValue() {
        trace("parseValue");

        // 1. Consume any NEWLINE tokens that precede the value
        while (check(Tokenizer.TokenType.NEWLINE)) {
            advance();
        }

        // 2. Check for Flow/Block Sequence and Flow Map (Simple consumption)
        if (check(Tokenizer.TokenType.SEQUENCE_START)) { // Flow Sequence: [...]
            return parseFlowSequence();
        }
        if (check(Tokenizer.TokenType.MAP_START)) { // Flow Map: {...}
            return parseFlowMap();
        }

        // FIX: Re-enable the check for block sequences that are not preceded by an INDENT.
        // This handles structures like `key: - item`
        if (check(Tokenizer.TokenType.SEQUENCE_ENTRY_INDICATOR)) { // Block Sequence: - item
            return parseBlockSequence();
        }

        // 3. CHECK FOR NESTED BLOCK MAP/SEQUENCE INDENTATION
        // This handles structures like `key:\n  - item`
        if (check(Tokenizer.TokenType.INDENT)) {

            // Check for Block Sequence: INDENT + sequence indicator (-)
            if (checkNext(Tokenizer.TokenType.SEQUENCE_ENTRY_INDICATOR)) {
                 // **CHANGE:** REMOVE the consume(INDENT) here.
                 // We let parseBlockSequence handle the INDENT and the DEDENT.
                 // consume(Tokenizer.TokenType.INDENT, "Expected indentation before block sequence."); // << REMOVE THIS LINE
                 return parseBlockSequence();
            }

            // Check for Block Map: INDENT + SCALAR (the key).
            if (checkNext(Tokenizer.TokenType.SCALAR)) {
                 return parseBlockMap(); // parseBlockMap consumes the INDENT itself.
            }

            // If INDENT is found but not followed by SCALAR or '-', it's an error.
            throw new ParseException("Indentation followed by ambiguous or invalid structure.", peek());
        }

        // 4. CHECK FOR SINGLE-LINE BLOCK MAPPING ENTRY (e.g., sequence item: "- key: value")
        // This MUST come before the simple SCALAR check below.
        Tokenizer.Token nextSignificantToken = peekAfterNewlines();
        if (check(Tokenizer.TokenType.SCALAR) && nextSignificantToken.type() == Tokenizer.TokenType.KEY_INDICATOR) {
            // The value is a single map entry, which might continue as a block map.
            return parseSingleBlockMappingEntry();
        }

        // 5. Check for Scalar (Default/Fallback)
        if (check(Tokenizer.TokenType.SCALAR,
                  Tokenizer.TokenType.ANCHOR,
                  Tokenizer.TokenType.ALIAS)) {
            return parseScalarNode();
        }

        throw new ParseException("Expected a map, sequence, or scalar value.", peek());
    }

    /**
     * Parses a mapping entry (SCALAR: VALUE) that may be the start of a multi-line
     * block map (e.g., a map used as a sequence item).
     */
    private YamlMap parseSingleBlockMappingEntry() {
        trace("parseSingleBlockMappingEntry");
        YamlMap map = new YamlMap();

        // 1. Parse the initial SCALAR:VALUE entry.
        YamlNode key = parseScalarNode(); // Consumes SCALAR (e.g., 'source')

        // Consume Newlines between key and colon (if any)
        while (check(Tokenizer.TokenType.NEWLINE)) {
            advance();
        }

        // Consume Colon
        consume(Tokenizer.TokenType.KEY_INDICATOR, "Expected ':' after map key.");

        // Consume NEWLINEs before the value, which is crucial for multi-line block values.
        while (check(Tokenizer.TokenType.NEWLINE)) {
            advance();
        }

        YamlNode value = parseValue(); // Consumes the first value (e.g., '~/Dokumente/Karten/Routen')
        YamlMappingEntry entry = new YamlMappingEntry();
        entry.addChild(key);
        entry.addChild(value);
        map.addEntry(entry);
        // map.addChild(entry); // Removed: Fixes duplication, but relies on YamlMap.getChildren() override

        // 2. Check for map continuation (e.g., 'destination: /media/...')

        // Consume any NEWLINEs after the value
        while (check(Tokenizer.TokenType.NEWLINE)) {
            advance();
        }

        // If the next token is an INDENT, it means the map continues on the next indented line.
        if (check(Tokenizer.TokenType.INDENT)) {
            // Call parseBlockMap, which consumes the INDENT and parses all subsequent
            // indented key-value pairs until it encounters DEDENT.
            YamlMap continuationMap = parseBlockMap();

            // Merge all entries from the continuation map into the initial map by iterating.
            for (YamlMappingEntry continuedEntry : continuationMap.getEntries()) {
                map.addEntry(continuedEntry);
                // map.addChild(continuedEntry); // Removed: Fixes duplication
            }
        }

        return map;
    }


    private YamlMap parseRootBlockMap() {
        trace("parseRootBlockMap");
        YamlMap rootMap = new YamlMap();

        while (!check(Tokenizer.TokenType.EOF)) {
            trace("***");
            // 1. ITERATIVE CLEANUP: Consume any sequence of NEWLINEs or DEDENTs.
            while (check(Tokenizer.TokenType.NEWLINE) || check(Tokenizer.TokenType.DEDENT)) {
                 advance();
            }

            if (check(Tokenizer.TokenType.EOF)) {
                break;
            }

            // 2. Check for the next top-level key: SCALAR + KEY_INDICATOR
            Tokenizer.Token nextSignificantToken = peekAfterNewlines();

            if (check(Tokenizer.TokenType.SCALAR) && nextSignificantToken.type() == Tokenizer.TokenType.KEY_INDICATOR) {

                // Parse Key
                YamlNode key = parseScalarNode(); // Consumes SCALAR

                // Consume Newlines between key and colon (if any)
                while (check(Tokenizer.TokenType.NEWLINE)) {
                    advance();
                }

                // Consume Colon
                consume(Tokenizer.TokenType.KEY_INDICATOR, "Expected ':' after map key at root level.");

                // Parse Value (this will handle the subsequent NEWLINE and INDENT)
                // Consume NEWLINEs before the value, if any.
                while (check(Tokenizer.TokenType.NEWLINE)) {
                    advance();
                }

                // CRITICAL FIX: Check for missing value before calling parseValue.
                YamlNode value;
                if (check(Tokenizer.TokenType.SCALAR) && peekAfterNewlines().type() == Tokenizer.TokenType.KEY_INDICATOR ||
                    check(Tokenizer.TokenType.EOF)) {

                    // Value is missing (e.g., "key:\nnextkey:") -> assign null
                    value = new YamlScalar(null, YamlScalar.ScalarStyle.PLAIN);
                } else {
                    // Parse Value (this will handle the subsequent INDENT/data)
                    value = parseValue();
                }

                trace("##1");
                // Build Entry
                YamlMappingEntry entry = new YamlMappingEntry();
                entry.addChild(key);
                entry.addChild(value);
                rootMap.addEntry(entry);

                // rootMap.addChild(entry); // Removed: Fixes duplication, but relies on YamlMap.getChildren() override
            } else if (check(Tokenizer.TokenType.INDENT)) {
                 throw new ParseException("Unexpected indentation at root level.", peek());

            } else {
                throw new ParseException("Expected top-level map key or end of file.", peek());
            }
        }
        return rootMap;
    }


    private YamlMap parseBlockMap() {
        trace("parseBlockMap");
        // 1. Consume the mandatory INDENT token that started this block map.
        consume(Tokenizer.TokenType.INDENT, "Expected indentation to start map block.");

        YamlMap map = new YamlMap();

        while (true) {
            while (check(Tokenizer.TokenType.NEWLINE)) {
                 advance();
            }

            // 3. CHECK EXIT: Check for the end of the block (DEDENT) or EOF.
            if (check(Tokenizer.TokenType.DEDENT, Tokenizer.TokenType.EOF)) {
                break;
            }

            // 4. Validate and Parse the next entry.
            Tokenizer.Token nextSignificantToken = peekAfterNewlines();

            if (check(Tokenizer.TokenType.SCALAR) && nextSignificantToken.type() == Tokenizer.TokenType.KEY_INDICATOR) {

                YamlNode key = parseScalarNode(); // Consumes SCALAR

                // Consume Newlines between key and colon (if any)
                while (check(Tokenizer.TokenType.NEWLINE)) {
                    advance();
                }

                // Consume Colon
                consume(Tokenizer.TokenType.KEY_INDICATOR, "Expected ':' after map key.");

                // Consume NEWLINEs before the value, if any.
                while (check(Tokenizer.TokenType.NEWLINE)) {
                    advance();
                }

                // Parse Value (this will handle the subsequent NEWLINE and INDENT)
                YamlNode value;
                nextSignificantToken = peekAfterNewlines();

                // If the next token is the start of a new entry (SCALAR:KEY_INDICATOR)
                // OR the end of the current block (DEDENT/EOF), the value is implicit null.
                if ((check(Tokenizer.TokenType.SCALAR) && nextSignificantToken.type() == Tokenizer.TokenType.KEY_INDICATOR) ||
                    check(Tokenizer.TokenType.DEDENT) ||
                    check(Tokenizer.TokenType.EOF)) {

                    // Value is missing/null (e.g., "key:\nnextkey:")
                    value = new YamlScalar(null, YamlScalar.ScalarStyle.PLAIN);
                } else {
                    // Parse Value (this will handle the subsequent NEWLINE and INDENT)
                    value = parseValue();
                }

                // Build Entry
                YamlMappingEntry entry = new YamlMappingEntry();
                entry.addChild(key);
                entry.addChild(value);
                map.addEntry(entry);

                // map.addChild(entry); // Removed: Fixes duplication, but relies on YamlMap.getChildren() override
            } else {
                 throw new ParseException("Expected a map key or dedentation.", peek());
            }
        }

        // 5. Consume the mandatory DEDENT token that signals the end of this block map.
        consume(Tokenizer.TokenType.DEDENT, "Expected dedentation to end map block.");
        return map;
    }

    // FINAL STABILIZED VERSION
    private YamlSequence parseBlockSequence() {
        trace("parseBlockSequence");
        YamlSequence sequence = new YamlSequence();

        // **NEW:** Check if an INDENT token starts this sequence block.
        // This handles cases like `key: \n INDENT - item`.
        boolean wasIndented = check(Tokenizer.TokenType.INDENT);
        if (wasIndented) {
             consume(Tokenizer.TokenType.INDENT, "Expected indentation to start block sequence.");
        }

        while (true) {

            // 1. Pre-item Cleanup: Consume all NEWLINEs that separate sequence items.
            while (check(Tokenizer.TokenType.NEWLINE)) {
                advance();
            }

            // 2. CHECK EXIT: Stop if we hit a DEDENT or EOF.
            if (check(Tokenizer.TokenType.DEDENT, Tokenizer.TokenType.EOF)) {
                 break; // Leave DEDENT/EOF for the post-loop consumption/caller.
            }

            // 2b. CHECK IMPLICIT EXIT: If the tokenizer omits the DEDENT for the block sequence
            // and we hit the next map key in the parent block, we must stop and let the parent map
            // parse the key. This is indicated by SCALAR followed by KEY_INDICATOR.
            Tokenizer.Token nextSignificantToken = peekAfterNewlines();
            if (check(Tokenizer.TokenType.SCALAR) && nextSignificantToken.type() == Tokenizer.TokenType.KEY_INDICATOR) {
                 break;
            }

            // 3. Check for the item indicator.
            if (check(Tokenizer.TokenType.SEQUENCE_ENTRY_INDICATOR)) {
                advance(); // Consume the '-'

                // The value should start immediately after, possibly with NEWLINEs and INDENT
                YamlNode itemValue = parseValue();
                sequence.addItem(itemValue);

                // 4. Post-item cleanup: Consume ALL noise (NEWLINEs) before restarting the loop
                while (check(Tokenizer.TokenType.NEWLINE)) {
                    advance();
                }

            } else {
                // Found a token other than structural end (DEDENT/EOF or a parent key SCALAR) or '-' indicator. Error.
                throw new ParseException("Expected sequence entry indicator ('-') or end of block.", peek());
            }
        }

        // **CRITICAL FIX:** Consume DEDENT ONLY if we consumed an INDENT AND the DEDENT is present.
        if (wasIndented && check(Tokenizer.TokenType.DEDENT)) {
            consume(Tokenizer.TokenType.DEDENT, "Expected dedentation to end block sequence.");
        } else if (wasIndented && !check(Tokenizer.TokenType.EOF)) {
             // Optional: Add a check for a missing DEDENT if we expected one but found neither DEDENT nor EOF.
             // This can help catch errors in the tokenizer's block closing.
        }


        // The original logic that was commented out/removed is now integrated above:
        // consume(Tokenizer.TokenType.DEDENT, "Expected dedentation to end map block.");
        // Since we are now handling an implicit end by checking for the parent key, we must NOT consume DEDENT here.
        return sequence;
    }

    private YamlMap parseFlowMap() {
        trace("parseFlowMap");
        consume(Tokenizer.TokenType.MAP_START, "Expected '{' to start a flow map.");
        YamlMap map = new YamlMap();
        while (!check(Tokenizer.TokenType.MAP_END) && !isAtEnd()) {
            YamlNode key = parseScalarNode();
            consume(Tokenizer.TokenType.KEY_INDICATOR, "Expected ':' after map key in flow context.");
            YamlNode value = parseValue();
            YamlMappingEntry entry = new YamlMappingEntry();
            entry.addChild(key);
            entry.addChild(value);
            map.addEntry(entry);
            // map.addChild(entry); // Removed: Fixes duplication, but relies on YamlMap.getChildren() override
            if (check(Tokenizer.TokenType.COMMA)) {
                advance();
            } else if (!check(Tokenizer.TokenType.MAP_END)) {
                throw new ParseException("Expected ',' or '}' to continue/end flow map.", peek());
            }
        }
        consume(Tokenizer.TokenType.MAP_END, "Expected '}' to end flow map.");
        return map;
    }

    private YamlSequence parseFlowSequence() {
        trace("parseFlowSequence");
        consume(Tokenizer.TokenType.SEQUENCE_START, "Expected '[' to start a flow sequence.");
        YamlSequence sequence = new YamlSequence();
        while (!check(Tokenizer.TokenType.SEQUENCE_END) && !isAtEnd()) {
            YamlNode itemValue = parseValue();
            sequence.addItem(itemValue);
            if (check(Tokenizer.TokenType.COMMA)) {
                advance();
            } else if (!check(Tokenizer.TokenType.SEQUENCE_END)) {
                throw new ParseException("Expected ',' or ']' to continue/end flow sequence.", peek());
            }
        }
        consume(Tokenizer.TokenType.SEQUENCE_END, "Expected ']' to end flow sequence.");
        return sequence;
    }

    private YamlScalar parseScalarNode() {
        trace("parseScalarNode");
        Tokenizer.Token scalarToken = consume(Tokenizer.TokenType.SCALAR, "Expected a scalar value.");
        Object finalValue = scalarToken.value() != null
                            ? scalarToken.value()
                            : new TypeConverter().convert(scalarToken.lexeme());
        YamlScalar.ScalarStyle style = determineScalarStyle(scalarToken.lexeme());
        return new YamlScalar(finalValue, style);
    }

    private YamlScalar.ScalarStyle determineScalarStyle(String lexeme) {
        if (lexeme.startsWith("'")) return YamlScalar.ScalarStyle.SINGLE_QUOTED;
        if (lexeme.startsWith("\"")) return YamlScalar.ScalarStyle.DOUBLE_QUOTED;
        if (lexeme.startsWith("|")) return YamlScalar.ScalarStyle.LITERAL;
        if (lexeme.startsWith(">")) return YamlScalar.ScalarStyle.FOLDED;
        return YamlScalar.ScalarStyle.PLAIN;
    }

    // -------------------------------------------------------------------------
    // CORE PARSER ENGINE METHODS (Lookahead & Consumption)
    // -------------------------------------------------------------------------

    private Tokenizer.Token advance() {
        if (!isAtEnd()) {
            current++;
        }
        return tokens.get(current - 1);
    }

    private Tokenizer.Token peek() {
        if (current >= tokens.size()) {
            return tokens.get(tokens.size() - 1);
        }
        return tokens.get(current);
    }

    /**
     * Checks for a specific token type at a position that ignores intermediate NEWLINEs or DEDENTS.
     * Starts looking immediately after the current token (current + 1).
     */
    private Tokenizer.Token peekAfterNewlines() {
        trace("peekAfterNewlines");
        int lookahead = current + 1;

        // Skip newlines/dedents until a significant token is found
        while (lookahead < tokens.size() &&
               (tokens.get(lookahead).type() == Tokenizer.TokenType.NEWLINE ||
                tokens.get(lookahead).type() == Tokenizer.TokenType.DEDENT)) {
            lookahead++;
        }

        if (lookahead < tokens.size()) {
            return tokens.get(lookahead);
        }
        return tokens.get(tokens.size() - 1); // Return EOF token
    }

    private boolean check(Tokenizer.TokenType... types) {
        if (current >= tokens.size()) return false;
        Tokenizer.TokenType currentType = peek().type();
        for (Tokenizer.TokenType type : types) {
            if (currentType == type) {
                return true;
            }
        }
        return false;
    }

    private boolean checkNext(Tokenizer.TokenType type) {
        if (current + 1 >= tokens.size()) return false;
        return tokens.get(current + 1).type() == type;
    }

    private boolean isAtEnd() {
        return current >= tokens.size();
    }

    private Tokenizer.Token consume(Tokenizer.TokenType type, String message) {
        if (check(type)) {
            return advance();
        }
        throw new ParseException(message, peek());
    }

    // -------------------------------------------------------------------------
    // CUSTOM EXCEPTION & TYPE CONVERTER
    // -------------------------------------------------------------------------

    public static class ParseException extends RuntimeException {
        public ParseException(String message, Tokenizer.Token token) {
            super(String.format("Parser Error: %s at L:%d C:%d. Found: %s",
                                message,
                                token.line(),
                                token.column(),
                                token.type()));
        }
    }

    public static class TypeConverter {
        public Object convert(String lexeme) {
            if (lexeme.equalsIgnoreCase("null") || lexeme.equals("~")) {
                return null;
            }
            if (lexeme.equalsIgnoreCase("true") || lexeme.equalsIgnoreCase("false")) {
                return Boolean.parseBoolean(lexeme);
            }
            try {
                return Integer.parseInt(lexeme);
            } catch (NumberFormatException e) {
                try {
                    return Double.parseDouble(lexeme);
                } catch (NumberFormatException ignored) {
                    return lexeme;
                }
            }
        }
    }
}